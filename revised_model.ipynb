{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports for model running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "import io\n",
    "import sagemaker.amazon.common as smac\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_df = pd.read_csv('Data for HT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preview the first 5 rows of the data\n",
    "insurance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the dataset cells contain any null values within any columns\n",
    "insurance_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preprocessing and Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Since some columns contain non numerical data, convert all the columns to numerical which will reflect the values respectfully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GENDER\n",
    "[Male = 0 | Female = 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_df['Gender'] = insurance_df['Gender'].apply(lambda x: 0 if x == 'Male' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Smoking Status\n",
    "[never smoked = 0 | formerley smoked = 1 | smokes = 2 | unknown = 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_s(j):\n",
    "    if j == 'never smoked':\n",
    "        return 0\n",
    "    elif j == 'formerly smoked':\n",
    "        return 1\n",
    "    elif j == 'smokes':\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "\n",
    "insurance_df['Smoking Status'] = insurance_df['Smoking Status'].apply(condition_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Alchohol (Freq)\n",
    "[No = 0 | Rare = 1 | Daily = 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_al(al):\n",
    "    if al == 'No':\n",
    "        return 0\n",
    "    elif al == 'Rare':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "insurance_df['Alcohol (Freq)'] = insurance_df['Alcohol (Freq)'].apply(condition_al)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise Intensity \n",
    "[None = 0 | Moderate = 1 | Extreme = 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def condition_i(i):\n",
    "    if i == 'No':\n",
    "        return 0\n",
    "    elif i == 'Moderate':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "insurance_df['Exercise Intensity'] = insurance_df['Exercise Intensity'].apply(condition_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop the columns that are not relevant for fitting the model or have not been obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_df = insurance_df.drop(columns=['Exercise Type'])\n",
    "insurance_df = insurance_df.drop(columns=['Av. Sleep per Day'])\n",
    "insurance_df = insurance_df.drop(columns=['Av. Daily Kcal In'])\n",
    "insurance_df = insurance_df.drop(columns=['Drugs Freq()'])\n",
    "insurance_df = insurance_df.drop(columns=['Av. Daily Kcal Burn'])\n",
    "insurance_df = insurance_df.drop(columns=['Assured Cost'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the rows that will cause issue with taining the model, blank values or NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_df = insurance_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the testing and training data for the model at a 20-80 split respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataset with all augmented data without the insurance cost column for training and testing\n",
    "X = insurance_df.drop(columns=['Insurance Cost'])\n",
    "#use y as the ground truth for all corresponding values in X\n",
    "y = insurance_df['Insurance Cost']\n",
    "\n",
    "#Reshape the datasets so that they can be used in the model\n",
    "X = np.array(X).astype('float32')\n",
    "y = np.array(y).astype('float32')\n",
    "\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "#split the data to 20-80 for testing and training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start a sagemaker session and \n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "################# MUST BE CHANGED FOR FINAL IMPLEMENTATION #####################\n",
    "bucket = 'sagemaker-hacker-2'\n",
    "prefix = 'linear_learner'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure y_train is in vector format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a buffer for the training data to go to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buf = io.BytesIO()\n",
    "#write training data to buffer\n",
    "smac.write_numpy_to_dense_tensor(buf, X_train, y_train)\n",
    "buf.seek(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Store the training data in a specified folder #PLACEHOLDER - hack-train-data# in a specified s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'hack-train-data'\n",
    "\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', key)).upload_fileobj(buf)\n",
    "\n",
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket, prefix, key)\n",
    "print('uploaded training data location: {}'.format(s3_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print('Training uploaded will be uploaded to {}'.format(output_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify sagemaker algorithm linear-learner\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "container = get_image_uri(boto3.Session().region_name, 'linear-learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use ml.t3.medium as it is part of the free tier for sagemaker\n",
    "\n",
    "linear = sagemaker.estimator.Estimator(container,\n",
    "                                       role,\n",
    "                                       train_instance_count = 1,\n",
    "                                       train_instance_type = 'ml.m5.4xlarge',\n",
    "                                       output_path = output_location,\n",
    "                                       sagemaker_session = sagemaker_session)\n",
    "\n",
    "#features depend on the number of columns, since we have 11, use 11\n",
    "#num_models runs the model 32 times, so you can pick the best one\n",
    "linear.set_hyperparameters(feature_dim = 11,\n",
    "                          predictor_type = 'regressor',\n",
    "                          mini_batch_size = 100,\n",
    "                          epochs = 100,\n",
    "                          num_models = 32,\n",
    "                          loss = 'absolute_loss')\n",
    "\n",
    "linear.fit({'train': s3_train_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showcase predictions result of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array([r['score'] for r in result['predictions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up variables to use for prediction analysis\n",
    "y_predict_orig = scaler_y.inverse_transform(predictions)\n",
    "y_test_orig = scaler_y.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "#Root Means Squared Error\n",
    "RMSE = float(format(np.sqrt(mean_squared_error(y_test_orig, y_predict_orig)),'.3f'))\n",
    "#Means Squared Error\n",
    "MSE = mean_squared_error(y_test_orig, y_predict_orig)\n",
    "#Mean Absolute Error\n",
    "MAE = mean_absolute_error(y_test_orig, y_predict_orig)\n",
    "#R-Squared Score\n",
    "r2 = r2_score(y_test_orig, y_predict_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TERMINATE THE MODEL TO STOP RESOURCES BEING USED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regressor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
